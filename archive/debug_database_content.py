#!/usr/bin/env python3
"""
è°ƒè¯•æ•°æ®åº“å†…å®¹è„šæœ¬
æŸ¥çœ‹è´Ÿæ ·æœ¬æ•°æ®çš„æƒ…å†µ
"""

import sqlite3
import pandas as pd
from pathlib import Path
import json

def check_database_content():
    """æ£€æŸ¥æ•°æ®åº“å†…å®¹"""
    db_path = Path("data/mouse_data.db")
    
    if not db_path.exists():
        print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    print("ğŸ” æ£€æŸ¥æ•°æ®åº“å†…å®¹...")
    print(f"æ•°æ®åº“è·¯å¾„: {db_path}")
    
    try:
        conn = sqlite3.connect(db_path)
        
        # æ£€æŸ¥è¡¨ç»“æ„
        print("\nğŸ“‹ æ•°æ®åº“è¡¨ç»“æ„:")
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        
        for table in tables:
            table_name = table[0]
            print(f"\nè¡¨: {table_name}")
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"PRAGMA table_info({table_name});")
            columns = cursor.fetchall()
            for col in columns:
                print(f"  - {col[1]} ({col[2]})")
            
            # è·å–è®°å½•æ•°
            cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
            count = cursor.fetchone()[0]
            print(f"  è®°å½•æ•°: {count}")
        
        # æ£€æŸ¥featuresè¡¨çš„å…·ä½“å†…å®¹
        print("\nğŸ“Š featuresè¡¨è¯¦ç»†å†…å®¹:")
        
        # æ£€æŸ¥ç”¨æˆ·åˆ†å¸ƒ
        cursor.execute("""
            SELECT user_id, COUNT(*) as count 
            FROM features 
            GROUP BY user_id 
            ORDER BY count DESC
        """)
        user_distribution = cursor.fetchall()
        
        print("ç”¨æˆ·æ•°æ®åˆ†å¸ƒ:")
        for user_id, count in user_distribution:
            print(f"  - {user_id}: {count} æ¡è®°å½•")
        
        # æ£€æŸ¥ç‰¹å®šç”¨æˆ·çš„æ•°æ®
        target_user = "HUAWEI_1755014060"
        print(f"\nğŸ¯ ç›®æ ‡ç”¨æˆ· {target_user} çš„æ•°æ®:")
        
        cursor.execute("""
            SELECT user_id, timestamp, feature_vector 
            FROM features 
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT 5
        """, (target_user,))
        
        user_data = cursor.fetchall()
        print(f"æ‰¾åˆ° {len(user_data)} æ¡è®°å½•")
        
        for i, (user_id, timestamp, feature_vector) in enumerate(user_data):
            print(f"\nè®°å½• {i+1}:")
            print(f"  ç”¨æˆ·ID: {user_id}")
            print(f"  æ—¶é—´æˆ³: {timestamp}")
            print(f"  ç‰¹å¾å‘é‡é•¿åº¦: {len(feature_vector) if feature_vector else 0}")
            
            # å°è¯•è§£æç‰¹å¾å‘é‡
            if feature_vector:
                try:
                    features = json.loads(feature_vector)
                    print(f"  ç‰¹å¾æ•°é‡: {len(features)}")
                    print(f"  ç‰¹å¾ç¤ºä¾‹: {list(features.keys())[:5]}")
                except:
                    print("  ç‰¹å¾å‘é‡è§£æå¤±è´¥")
        
        # æ£€æŸ¥å…¶ä»–ç”¨æˆ·æ•°æ®ï¼ˆä½œä¸ºè´Ÿæ ·æœ¬ï¼‰
        print(f"\nğŸ” å…¶ä»–ç”¨æˆ·æ•°æ®ï¼ˆè´Ÿæ ·æœ¬ï¼‰:")
        
        cursor.execute("""
            SELECT user_id, COUNT(*) as count 
            FROM features 
            WHERE user_id != ? AND user_id NOT LIKE 'training_user%' AND user_id NOT LIKE 'test_user%'
            GROUP BY user_id 
            ORDER BY count DESC
        """, (target_user,))
        
        other_users = cursor.fetchall()
        print(f"æ‰¾åˆ° {len(other_users)} ä¸ªå…¶ä»–ç”¨æˆ·:")
        
        for user_id, count in other_users:
            print(f"  - {user_id}: {count} æ¡è®°å½•")
        
        # æ£€æŸ¥è®­ç»ƒæ•°æ®
        print(f"\nğŸ“š è®­ç»ƒæ•°æ®:")
        
        cursor.execute("""
            SELECT user_id, COUNT(*) as count 
            FROM features 
            WHERE user_id LIKE 'training_user%'
            GROUP BY user_id 
            ORDER BY count DESC
        """)
        
        training_data = cursor.fetchall()
        print(f"æ‰¾åˆ° {len(training_data)} ä¸ªè®­ç»ƒç”¨æˆ·:")
        
        for user_id, count in training_data:
            print(f"  - {user_id}: {count} æ¡è®°å½•")
        
        # æ£€æŸ¥æµ‹è¯•æ•°æ®
        print(f"\nğŸ§ª æµ‹è¯•æ•°æ®:")
        
        cursor.execute("""
            SELECT user_id, COUNT(*) as count 
            FROM features 
            WHERE user_id LIKE 'test_user%'
            GROUP BY user_id 
            ORDER BY count DESC
        """)
        
        test_data = cursor.fetchall()
        print(f"æ‰¾åˆ° {len(test_data)} ä¸ªæµ‹è¯•ç”¨æˆ·:")
        
        for user_id, count in test_data:
            print(f"  - {user_id}: {count} æ¡è®°å½•")
        
        conn.close()
        
        # åˆ†æé—®é¢˜
        print(f"\nğŸ” é—®é¢˜åˆ†æ:")
        
        total_other_users = sum(count for _, count in other_users)
        total_training_data = sum(count for _, count in training_data)
        
        print(f"å…¶ä»–ç”¨æˆ·æ•°æ®æ€»é‡: {total_other_users}")
        print(f"è®­ç»ƒæ•°æ®æ€»é‡: {total_training_data}")
        
        if total_other_users == 0 and total_training_data == 0:
            print("âŒ é—®é¢˜ç¡®è®¤: æ²¡æœ‰è´Ÿæ ·æœ¬æ•°æ®")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print("1. éœ€è¦æ”¶é›†å…¶ä»–ç”¨æˆ·çš„æ•°æ®")
            print("2. æˆ–è€…ç”Ÿæˆè®­ç»ƒæ•°æ®")
            print("3. æˆ–è€…ä½¿ç”¨å•ç±»åˆ†ç±»æ–¹æ³•")
        
        elif total_other_users == 0:
            print("âš ï¸  é—®é¢˜: æ²¡æœ‰å…¶ä»–ç”¨æˆ·æ•°æ®ï¼Œä½†æœ‰è®­ç»ƒæ•°æ®")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨è®­ç»ƒæ•°æ®ä½œä¸ºè´Ÿæ ·æœ¬")
        
        else:
            print("âœ… æœ‰è¶³å¤Ÿçš„è´Ÿæ ·æœ¬æ•°æ®")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ•°æ®åº“å¤±è´¥: {e}")

def generate_test_negative_samples():
    """ç”Ÿæˆæµ‹è¯•ç”¨çš„è´Ÿæ ·æœ¬æ•°æ®"""
    print("\nğŸ”§ ç”Ÿæˆæµ‹è¯•ç”¨çš„è´Ÿæ ·æœ¬æ•°æ®...")
    
    db_path = Path("data/mouse_data.db")
    
    if not db_path.exists():
        print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    try:
        conn = sqlite3.connect(db_path)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è´Ÿæ ·æœ¬æ•°æ®
        cursor = conn.cursor()
        cursor.execute("""
            SELECT COUNT(*) FROM features 
            WHERE user_id LIKE 'negative_sample%'
        """)
        
        existing_count = cursor.fetchone()[0]
        
        if existing_count > 0:
            print(f"âœ… å·²å­˜åœ¨ {existing_count} æ¡è´Ÿæ ·æœ¬æ•°æ®")
            conn.close()
            return
        
        # è·å–ä¸€ä¸ªæ­£æ ·æœ¬ä½œä¸ºæ¨¡æ¿
        cursor.execute("""
            SELECT feature_vector FROM features 
            WHERE user_id = 'HUAWEI_1755014060'
            LIMIT 1
        """)
        
        result = cursor.fetchone()
        if not result:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ­£æ ·æœ¬æ•°æ®ä½œä¸ºæ¨¡æ¿")
            conn.close()
            return
        
        # è§£æç‰¹å¾å‘é‡
        template_features = json.loads(result[0])
        feature_names = list(template_features.keys())
        
        print(f"ä½¿ç”¨ {len(feature_names)} ä¸ªç‰¹å¾ç”Ÿæˆè´Ÿæ ·æœ¬")
        
        # ç”Ÿæˆè´Ÿæ ·æœ¬æ•°æ®
        import numpy as np
        from datetime import datetime, timedelta
        
        negative_samples = []
        base_time = datetime.now()
        
        for i in range(50):  # ç”Ÿæˆ50ä¸ªè´Ÿæ ·æœ¬
            # ä¸ºæ¯ä¸ªç‰¹å¾æ·»åŠ éšæœºå™ªå£°
            noisy_features = {}
            for feature_name in feature_names:
                base_value = template_features.get(feature_name, 0.0)
                # æ·»åŠ è¾ƒå¤§çš„å™ªå£°æ¥æ¨¡æ‹Ÿä¸åŒç”¨æˆ·çš„è¡Œä¸º
                noise = np.random.normal(0, 0.5)  # è¾ƒå¤§çš„å™ªå£°
                noisy_features[feature_name] = base_value + noise
            
            # åˆ›å»ºè´Ÿæ ·æœ¬è®°å½•
            negative_sample = {
                'user_id': f'negative_sample_{i+1:03d}',
                'timestamp': (base_time + timedelta(minutes=i)).isoformat(),
                'feature_vector': json.dumps(noisy_features)
            }
            
            negative_samples.append(negative_sample)
        
        # æ’å…¥è´Ÿæ ·æœ¬æ•°æ®
        cursor.executemany("""
            INSERT INTO features (user_id, timestamp, feature_vector)
            VALUES (?, ?, ?)
        """, [(sample['user_id'], sample['timestamp'], sample['feature_vector']) 
              for sample in negative_samples])
        
        conn.commit()
        conn.close()
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(negative_samples)} æ¡è´Ÿæ ·æœ¬æ•°æ®")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè´Ÿæ ·æœ¬æ•°æ®å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ•°æ®åº“å†…å®¹è°ƒè¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥æ•°æ®åº“å†…å®¹
    check_database_content()
    
    # ç”Ÿæˆæµ‹è¯•è´Ÿæ ·æœ¬
    generate_test_negative_samples()
    
    print("\n" + "=" * 50)
    print("âœ… è°ƒè¯•å®Œæˆ")

if __name__ == '__main__':
    main()
